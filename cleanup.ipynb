{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18e3f898",
   "metadata": {},
   "source": [
    "This notebook is dedicated to cleaning the data I already have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c3a19c",
   "metadata": {},
   "source": [
    "<h1>Issue: Line breaks and commas within review text</h1>\n",
    "Solution: need to go through each review and ensure correct formatting. The parameter encoding=\"utf-8\" in to_csv() should force that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc3f6791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the filename of the CSV to clean\n",
    "toClean = \"lower_threshold.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda718a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Force proper quoting and remove stray characters\n",
    "df = pd.read_csv(toClean)\n",
    "df.to_csv(toClean, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9596e67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(toClean, engine=\"python\", quotechar='\"', on_bad_lines=\"skip\")\n",
    "\n",
    "# Replace all newlines \\r \\n with spaces\n",
    "df = df.replace({r'[\\r\\n]+': ' '}, regex=True)\n",
    "\n",
    "df.to_csv(toClean, index=False, encoding=\"utf-8\", quoting=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6913dc0b",
   "metadata": {},
   "source": [
    "<h1>Issue: Remove unnecessary columns</h1>\n",
    "We don't really need to keep track of the authorAttribution, flagContentUri, nor googleMapsUri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c1047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(toClean, quoting=1, encoding=\"utf-8\")\n",
    "\n",
    "df.drop(columns=[\"authorAttribution\", \"flagContentUri\", \"googleMapsUri\", \"relativePublishTimeDescription\"], inplace=True)\n",
    "\n",
    "df.to_csv(toClean, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a2214",
   "metadata": {},
   "source": [
    "<h1>Issue: column count inconsistent between rows</h1>\n",
    "This issue stems from the first issue about line breaks and unescaped commas. The following script counts the number of columns in each row. If we see more than one number in set(counts), we know there are some rows in there that don't have the right amount of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c119887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{8}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(toClean, encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    counts = [len(row) for row in reader]\n",
    "print(set(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d6dc66",
   "metadata": {},
   "source": [
    "<h1>Issue: Should convert from wide format to long format</h1>\n",
    "Originally, the data we collected was in the wide format (one row per restaurant, many columns). This is suboptimal for data visualization purposees. So, we'll reshape our .csv into a long format and keep track of scores for the same restaurant by restaurant name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aac18f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(toClean)\n",
    "\n",
    "score_columns = [\"food\", \"service\", \"price\", \"drink\", \"restaurant\", \"expectation\",\n",
    "                 \"flavor\", \"staff\", \"parking\", \"ambience\", \"value\", \"recommendation\"]\n",
    "\n",
    "df_long = pd.melt(df,\n",
    "                  id_vars=[\"name\", \"rating\", \"text\", \"originalText\", \"publishTime\"],\n",
    "                  value_vars=score_columns,\n",
    "                  var_name=\"score_type\",\n",
    "                  value_name=\"score\")\n",
    "\n",
    "df_long.to_csv(toClean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e493f127",
   "metadata": {},
   "source": [
    "<h1>Issue: Raw ABSA results have np.float32() wrappers that cannot be ast.literal_eval()'d.</h1>\n",
    "We'll remove and replace them with regular floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c23338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'food': ('positive', 0.9476525),\n",
       " 'service': ('positive', 0.9842784),\n",
       " 'price': ('positive', 0.62646586),\n",
       " 'parking': ('negative', 0.49753693)}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "\n",
    "def parse_results(val):\n",
    "    if isinstance(val, dict):\n",
    "        return val\n",
    "    cleaned = re.sub(r\"np\\.float32\\((.*?)\\)\", r\"\\1\", val)\n",
    "    return ast.literal_eval(cleaned)\n",
    "\n",
    "df['results'] = df['results'].apply(parse_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c87153d",
   "metadata": {},
   "source": [
    "<h1>Issue: Raw ABSA results are dicts.</h1>\n",
    "We'll go through the dataframe and convert the results into regular scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495b50d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                0\n",
       "name                                    ChIJUaS2CnRskFQRgkVy8FFKcKE\n",
       "rating                                                            4\n",
       "text              They have very nice grab n go options but are ...\n",
       "originalText      {'text': 'They have very nice grab n go option...\n",
       "publishTime                             2025-05-08T21:42:41.981034Z\n",
       "food                                          (positive, 0.9476525)\n",
       "service                                       (positive, 0.9842784)\n",
       "price                                        (positive, 0.62646586)\n",
       "parking                                      (negative, 0.49753693)\n",
       "drink                                                           NaN\n",
       "restaurant                                                      NaN\n",
       "expectation                                                     NaN\n",
       "flavor                                                          NaN\n",
       "value                                                           NaN\n",
       "staff                                                           NaN\n",
       "ambience                                                        NaN\n",
       "recommendation                                                  NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "df = pd.read_csv(toClean)\n",
    "\n",
    "expanded = pd.json_normalize(df['results'])\n",
    "\n",
    "df = df.drop(columns=['results']).join(expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c86e2450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_to_score(value):\n",
    "    if isinstance(value, tuple):\n",
    "        label, score= value\n",
    "        if label == 'positive':\n",
    "            if score <= 1:\n",
    "                score *= 100\n",
    "            return score\n",
    "        elif label == 'negative':\n",
    "            if score <= 1:\n",
    "                score *= 100\n",
    "            return -score\n",
    "        elif label == 'neutral':\n",
    "            return 0.0\n",
    "    return value\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "32482e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'name',\n",
       " 'rating',\n",
       " 'text',\n",
       " 'originalText',\n",
       " 'publishTime',\n",
       " 'food',\n",
       " 'service',\n",
       " 'price',\n",
       " 'parking',\n",
       " 'drink',\n",
       " 'restaurant',\n",
       " 'expectation',\n",
       " 'flavor',\n",
       " 'value',\n",
       " 'staff',\n",
       " 'ambience',\n",
       " 'recommendation']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7203cded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy-\\AppData\\Local\\Temp\\ipykernel_108800\\1754717476.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[absa_columns] = df[absa_columns].applymap(sentiment_to_score)\n"
     ]
    }
   ],
   "source": [
    "absa_columns = ['food', 'service', 'ambience', 'staff', 'price', 'value', 'restaurant', 'recommendation',\n",
    "                'parking', 'drink', 'expectation', 'flavor']\n",
    "df[absa_columns] = df[absa_columns].applymap(sentiment_to_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7714bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(toClean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80febf4e",
   "metadata": {},
   "source": [
    "<h1>Issue: assign human-readable place name, longitude, and latitude to each review by ID</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7240463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "places_df = pd.read_csv(\"places.csv\")\n",
    "threshold_df = pd.read_csv(\"lower_threshold.csv\")\n",
    "\n",
    "merged_df = threshold_df.merge(\n",
    "    places_df[['id', 'displayName', 'longitude', 'latitude']],\n",
    "    left_on='name',\n",
    "    right_on='id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# drop the dupllicate ID column\n",
    "merged_df = merged_df.drop(columns='id')\n",
    "merged_df.to_csv(\"lower_threshold_with_coords.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "belleviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
